# Summary

| Date  | Notes
| :---- | :----
| 05/20 | 
| 05/21 | 
| 05/22 | 
| 05/23 | 
| 05/24 |  

# Activity
    
## Monday - 5/20

- I decided to move on from training my own model to be better at deciding where someone's eyes are. I decided to attempt to control my mouse in a very simple manner and just have it navigate throughout the screen just by using my eyes.    
    - I decided to try using pyautogui first to see whether this would be the best approach.


- Ok. Now I want to decide how I will be sending commands in the first place. Let's say I am tracking my eyes via my own webcam. If I want to decide where I am facing and what we should do. What is the best way to approach this. 
    - 1. I can write a script that takes multiple pictures after giving the user a prompt of where to look. It'll kind of treat this like a calibration, and build a dataset that is labeled. I can then train a model based on this calibration and it'll be able to decide where exactly the user is looking.
    - 2. I can overlay a crosshair over the user's eye and then I can use this image to send information to a python script with the number of pixels that are in a certain quadrant. Based on this I can then calculate where the user is facing.
        - The only problem with this approach is blinking and looking down leads to some noisy data.

    - Second approach with a weighted sum of the pixels.

- Based on either of these approaches. I want to first print out where exactly we are facing and our confidence that we are indeed looking in that direction. I then want these commands to be logged when I blink twice rapidly. 
    - I then want to allow my eye movement to allow my mouse to move using pyautogui as stated above originally.


    - Ask Papoutsaki for the processing of eyes.


- I realized that my window that shows my eyes as the main focus actually makes it hard for the vertical length of the line to change which makes it a bit harder to tell.
    - Can I use both masks to detect when I'm blinking vs when I'm not.

Final Python Script that I want to use:
    - I want to use my facial landmarks and eye orientation from trackingEyes.py
    - I want to use my facial masking from maskFacialLandmarks.py
    - I want to use the multithreading from theadingMultiCameras.py
    - I want to use the crosshair detection and gaze detection from gaze.py


## Tuesday - 5/21

- I continued working on my finalized python file that brings together everything I have learned so far. I got the facial masking of images working alongside adding some customization for making crosshairs.
- I finished enabling threading and combining all the neccessary features for me to start working on sending commands to python.
    - I will now count the number of pixels in a certain quadrant and say our confidence that we are facing in that specific direction

## Wednesday - 5/22

- Continued working on a system that is able to count the number of pixels in relation to the crosshair laid on top of each image of the eyes. I originally tried counting the number of black pixels on the masked image, but I realized it was counting the total number of black pixels including those found in the background, so I added a different return to the mask function which returned an image with a white background to make it easier to count the number of black pixels. 
    - The different iterations of functions that I would make wouldn't always work as intended they would always count things leaning towards some quadrant never recognizing any that were anywhere else.
    - I kept reworking the system and making it such that each eye was independent from one another to allow more accurate black pixel counting. I then finally got a system that recognized all directions but required very exaggerated eye movement. 
    - I will continue fine tweaking in the future but for now I wish to move to ensure I accomplish everything I want.

## Thursday - 5/23

- After finishing up the first draft of my gaze detection. I decided now is the best time to focus on sending commands to python and having my cursor interact with the computer in a specific way.
- I also thought about what materials I would need to construct a simple robot.
    - I would make a very simple one. Two wheels with two motors and a drive ball at the front. It would need to have a microcomputer or board that allows for communication with a python script either via wifi or bluetooth and have a port to connect motors and a camera. I must also think about how I would supply power to it.


    - Zoom in on the eyes


    - Actual Communication: Socket Programming (could be done implies own protocols.) 

    - Reccommend: 
    - SSH tunnel (higher level API using sockets underneath) -> can open up tunnels to the remote computer. Have raspberry pi and computer on the same wifi network and send messages to each other via sending messages to a file.
    - ROS say send message and receive message (high level API). Standard message that is a part of ROS.
        - Heavy Weight. 
        - Search Communciate over SSH interprocess communication over SSH IPC/RPC (Haven't done them RPC might be the easiest way to do it create a json object and an RPC object will send and recieve it (more lightweight) ).


    - Read a bit more on them and go from there.

    - Tunnel Cable
    - Nvidia Jetson.
    - Vector Graphic 




## Friday - 5/24


- I continued working in the iris detection to improve my gaze detection.
- Don't plugin the jetbot directly into usb 


- In order to connet the barrel jack to the Jetson Nano B01 board we have to ensure that if the developer kit’s total load is expected to exceed 2A, e.g., due to peripherals attached to the carrier board, connect the J48 Power Select Header pins to disable power supply via Micro-USB and enable 5V⎓4A via the J25 power jack. Another option is to supply 5V⎓5A via the J41 expansion header (2.5A per pin).
    - We originally thought that the board has 3 pins; however, there were only 2 with the jumper hanging off one pin.
    - We moved the jumper down to cover both pins and got the barrel jack power working.    

- It is recommended we shut tdown the computer and unplug the power when connecting peripherals. 
    - I do so and then conneted the ethernet cable; however, after doing so and trying to activate the connection it would not connect to the internet whatsoever. I attempted a restart and terminal commands to activate the connection with `sudo nmtui` but it still did not work.
    - I changed the ethernet port that the jetson was connected to and it ended up actually allowing me to activate the ethernet connection. However, it kept disconnecting me from the wifi over and over again. I realized that I needed to activate via Network Access Control on Pomona's website.
        - I was given two options Pomona College Community or Gaming Consoles. I registered it as both and both already said it was registered, yet it was still unable to connect to wifi.
        - I then found a guide that I started to follow but I kept comming across the same error where 
        ```
        Reading package lists… Done
        E: The repository ‘https://repo.download.nvidia.com/jetson/common 17 r32.5 Release’ no longer has a Release file.
        N: Updating from such a repository can’t be done securely, and is therefore disabled by default.
        N: See apt-secure(8) manpage for repository creation and user configuration details.
        E: The repository ‘https://repo.download.nvidia.com/jetson/t210 15 r32.5 Release’ no longer has a Release file.
        N: Updating from such a repository can’t be done securely, and is therefore disabled by default.
        N: See apt-secure(8) manpage for repository creation and user configuration details.
        ```
        - I got assitance from Professor Clark and found that the time of the machine was correct but the device date was off by a month which once it was corrected, fixed the issue.
        - I updated the Ubuntu on the jetbot, I then upgraded the firmware, and finally installed the neccessary wifi drivers. Finally, I was able to get wifi working on the jetbot.
# Issues

- Blinking is really inconsistent. I want to try to get that fixed to finally move on .

# Plans

