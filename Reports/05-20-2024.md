# Summary

| Date  | Notes
| :---- | :----
| 05/20 | 
| 05/21 | 
| 05/22 | 
| 05/23 | 
| 05/24 |  

# Activity
    
## Monday - 5/20

- I decided to move on from training my own model to be better at deciding where someone's eyes are. I decided to attempt to control my mouse in a very simple manner and just have it navigate throughout the screen just by using my eyes.    
    - I decided to try using pyautogui first to see whether this would be the best approach.


- Ok. Now I want to decide how I will be sending commands in the first place. Let's say I am tracking my eyes via my own webcam. If I want to decide where I am facing and what we should do. What is the best way to approach this. 
    - 1. I can write a script that takes multiple pictures after giving the user a prompt of where to look. It'll kind of treat this like a calibration, and build a dataset that is labeled. I can then train a model based on this calibration and it'll be able to decide where exactly the user is looking.
    - 2. I can overlay a crosshair over the user's eye and then I can use this image to send information to a python script with the number of pixels that are in a certain quadrant. Based on this I can then calculate where the user is facing.
        - The only problem with this approach is blinking and looking down leads to some noisy data.

    - Second approach with a weighted sum of the pixels.

- Based on either of these approaches. I want to first print out where exactly we are facing and our confidence that we are indeed looking in that direction. I then want these commands to be logged when I blink twice rapidly. 
    - I then want to allow my eye movement to allow my mouse to move using pyautogui as stated above originally.


    - Ask Papoutsaki for the processing of eyes.

## Tuesday - 5/21

## Wednesday - 5/22

## Thursday - 5/23

## Friday - 5/24

# Issues

- Blinking is really incosistent. I want to try to get that fixed to finally move on .

# Plans

# Relevant Readings

# Lit Review Reflection
