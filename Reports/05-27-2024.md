# Summary

| Date  | Notes
| :---- | :----
| 05/27 | Memorial Day
| 05/28 | Read RPC documentation; fixed camera path issue; used pyautogui to control mouse by blinking; reset Jetson Nano date/time and installed Python 3.6.9.
| 05/29 | Improved eye tracking sensitivity; worked on Jetson Nano wifi setup; read Jetson Nano documentation; got wifi working on Jetson Nano.
| 05/30 | Attempted Docker setup on Jetson Nano; faced issues running Python scripts; camera not recognized by OpenCV; confirmed hardware working; gave Unreal Engine 5 tour.
| 05/31 | Solved 'Illegal instruction (core dumped)' error on Jetson Nano; faced issues with qwiic motor driver; found hardware recognition issues; recognized motor driver but not motors.

# Activity
    
## Monday - 5/27

- Memorial Day

## Tuesday - 5/28

- Began reading documentation on Remote Procedure Call (RPC) to facilitate command exchange between different Python scripts.
    - Identified potential latency issues with RPC and considered alternative methods for more efficient data transmission.

- Encountered an issue with the camera turning on but displaying a gray screen instead of frames.
    - Traced the issue to an incorrect file path in the face detection and landmarks file, corrected the path, and resolved the issue.

- Shifted focus to using pyautogui to control the mouse via a Python script in a while loop.
    - Created a new file to detect user blinking and move the mouse left when a blink is detected.
    - Confirmed the basic functionality and planned to refine the code to incorporate gaze direction.

- Powered on the robot and reset the date and time to ensure proper Wi-Fi functionality.
- Installed Python 3.6.9 on the system.

## Wednesday - 5/29

- **Goals for today:**
    - Increase eye tracking sensitivity to reduce the need for exaggerated movements.
    - Implement iris-based eye tracking.
    - Configure the robot to run a simple Python script.
    - Ensure the motor and camera function independently on the robot.

- **Issues:** The calibration is tailored to my own eyes, resulting in reduced accuracy for others.

- Adjusted thresholds for eye tracking to improve sensitivity and enhance mouse control.
- Shifted focus to configuring the robot, including steps to enable Wi-Fi.
- Reviewed documentation on programming and running Python scripts on the device.

- Successfully established an SSH connection for remote access:
    ```bash
    ssh -L 8001:localhost:8001 <username>@<hostname>
    ```

- Enabled Wi-Fi on the Jetson Nano and began setting up a live video feed from the Jetson Nano to my laptop.

- Followed this [Docker setup tutorial](https://jetbot.org/master/software_setup/docker.html) for the Jetson Nano:
    - Username: ARCS
    - Encountered persistent "image not found" errors, causing setup delays.

## Thursday - 5/30

- **Docker Setup Attempts**: Continued efforts to configure Docker for online programming across devices were unsuccessful.
    - Shifted focus to running Python files directly from the terminal, but encountered issues with the camera not being read correctly by OpenCV.
    - Verified that the camera hardware was functioning by using the command `nvgstcapture-1.0`.

- **Unreal Engine 5 Tour**: Provided a tour of Unreal Engine 5 to Kellie and Tommy, covering:
    - Logging in and user interface controls.
    - Benefits and use cases of Unreal Engine.
    - Available commands: `ke * texture [0-2] [0-40]`.
    - Process of creating models and hitboxes.
    - Logic behind our control mechanisms.
    - Blueprint creation and usage.

- **Documenting Jetbot Setup**:
    - To log in to the Jetbot, use the credentials found in the appropriate document.
    - For Wi-Fi connection, ensure the Jetbot is connected to the second available Pomona Network option.
    - Ensure the date and time are set correctly. Useful resources for the Jetbot:
        - [First Picture CSI-USB Camera](https://developer.nvidia.com/embedded/learn/tutorials/first-picture-csi-usb-camera)
        - [Jetson Inference Streaming](https://github.com/dusty-nv/jetson-inference/blob/master/docs/aux-streaming.md#v4l2-cameras)
        
## Friday - 5/31
- **OpenCV and GStreamer Issue**: Researched and addressed the 'Illegal instruction (core dumped)' error:
    - Reference: [NVIDIA Developer Forum](https://forums.developer.nvidia.com/t/opencv-video-capture-with-gstreamer-doesnt-work-on-ros-melodic/113147)
    - Solution: [Stack Overflow link](https://stackoverflow.com/questions/65631801/illegal-instructioncore-dumped-error-on-jetson-nano)
- **Environment Setup**: Created a new environment named `jetbot_env`.
- **Qwiic Driver Issues**: Encountered significant problems with importing `qwiic`, spending 3 hours troubleshooting:
    - The error persisted despite multiple restarts, reinstallations, and attempts to install locally from GitHub.
    - Determined that the Jetbot was not recognizing some of its hardware components. Specifically, the Sparkfun Qwiic motor driver was not recognized. After downloading additional libraries, the motor driver controller was recognized, but the motors connected to it were not.

# Issues
- **Blinking Detection**: Blinking detection is inconsistent; need to improve accuracy.

# Plans
- **Python Script Communication**: Develop a script for data communication between Python scripts.
- **Jetson Nano Eye Tracking**: Deploy eye tracking data script on Jetson Nano; receive live feed from the robot.
- **Motor Control**: Get motors working through Python commands on Jetson Nano.
